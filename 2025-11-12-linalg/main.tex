\documentclass[a4paper, 12pt]{article}

\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[danish]{babel} %[british, UKenglish, USenglish, english, american]

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

\usepackage{fancyhdr}
\pagestyle{fancy}
%\geometry{verbose,tmargin=3cm,bmargin=3cm, lmargin=2.5cm, rmargin=2.5cm,headheight=1.5cm,headsep=1.5cm}

\usepackage{graphicx}
\usepackage{float}
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

\usepackage{lastpage}
\usepackage{listings}


\usepackage{enumitem}
\numberwithin{equation}{section}
\theoremstyle{plain}
\newtheorem{saetning}{Sætning}[section]
\newtheorem{lemma}[saetning]{Lemma}
\newtheorem{korollar}[saetning]{Korollar}
\newtheorem{proposition}[saetning]{Proposition}

\theoremstyle{definition}
\newtheorem{observation}[saetning]{Observation}
\newtheorem{definition}[saetning]{Definition}
\newtheorem{eksempel}[saetning]{Eksempel}
\newtheorem{notation}[saetning]{Notation}

\crefname{equation}{ligning}{ligninger}
\DeclarePairedDelimiter{\ps}{(}{)}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\usepackage{nicematrix}
\usepackage{exercise}
\renewcommand{\ExerciseName}{Opgave}
\renewcommand{\ExerciseListName}{Opg.}
\renewcommand{\AnswerName}{Svar}
\renewcommand{\AnswerListName}{Svar}
\renewcommand{\ExePartName}{Del}

%\setlength\parindent{0pt} % ingen indention ved linjeskift

\lhead{UNF Odense Matematikklub}
\chead{}
\rhead{Lineær Algebra}
\cfoot{\thepage\ af \pageref{LastPage}}


\title{UNF Odense Matematikklub: Lineær Algebra}
\author{\href{mailto:matklub@odense.unf.dk}{matklub@odense.unf.dk}}
\date{}


\begin{document}
\NiceMatrixOptions
  {
    code-for-first-col = \scriptstyle ,
    code-for-first-row = \scriptstyle 
  }

\maketitle{}
\thispagestyle{empty}

\pagenumbering{gobble}
\clearpage
\pagenumbering{arabic}
%start på dokument
\newpage
\section{Systemer af lineære ligninger}
Du er sikkert stødt på 2 lineære ligninger i to ubekendte. Et eksempel er
\[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&+&y&=&-3\\
    4x&-&2y&=&-9
  \end{array}
\]
Vi ved hvordan man løser disse ligninger, hvis altså de har en løsning. Vi kan først isolere \(x\) i den første ligning:
\begin{align*}
  2x+y=-3\\
  \Rightarrow 2x=-3-y\\
  \Rightarrow x=\frac{-3}{2}-\frac{y}{2}.
\end{align*}
Vi kan sætte dette udtryk for \(x\) ind i ligning 2 og isolere \(y\).
\begin{align*}
  4\ps*{\frac{-3}{2}-\frac{y}{2}}-2y=-9\\
  \Rightarrow -6-2y-2y=-9\\
  \Rightarrow -4y=-3\\
  \Rightarrow y = \frac{3}{4}.
\end{align*}
Vi har fundet \(y\). Vi kan nu indsætte \(y\) i den første ligning igen for at finde \(x\).
\begin{align*}
  2x+\frac{3}{4}=-3\\
  \Rightarrow 2x=-\frac{15}{4}\\
  \Rightarrow x=-\frac{15}{8}.
\end{align*}
Denne proces er dog lidt nørklet. Desuden kan man overveje følgende:
\begin{quote}
  \emph{Hvad nu hvis man havde 3 lineære ligninger i 3 ubekendte? Eller \(n\) ligninger i \(n\) ubekendte for \(n\ge 3\)?}
\end{quote}
Godt nok kan man lave en lignende proces, men det bliver kun mere nørklet jo flere ligninger man tilføjer. Det er i denne slags situation at man som matematiker bør overveje
\begin{quote}
  \emph{Findes der en nemmere og mere generel måde at løse denne slags ligninger på?}
\end{quote}
Og, da matematikere er dovne, ønsker vi særligt en metode som kræver mindre tankevirksomhed. Heldigvis er svaret på vores spørgsmål et klart ``ja!'', og vi vil nu beskæftige os med en måde at gøre det på, kaldet \emph{Gau\ss-(Jordan) elimination}.

Vi skal dog først være præcise om hvad vi mener med lineære ligningssystemer
\begin{definition}
  En reel lineær ligning i variablene \(x_1,x_2,\ldots,x_n\) er en ligning på formen
  \[
    a_1x_1+a_2x_2+\cdots+a_nx_n=b,
  \]
  Hvor \(a_1,\ldots, a_n\) og \(b\) alle er reelle tal.

  Et lineært ligningssystem i \(x_1,\ldots x_n\) er en samling af lineære ligninger i \(x_1,\ldots,x_n\). En løsning på et sådant ligningssystem er et valg af konkrete reelle tal \(y_1,\ldots y_n\), så samtlige ligninger bliver sande, når man indsætter \(y_1,\ldots,y_n\) på \(x_1,\ldots,x_n\)'s pladser.
\end{definition}
\section{Matricer og Gau\ss-Jordan elimination}
\subsection*{Matricer}
Vi betragter igen vores ligningssystem
\[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&+&y&=&-3\\
    4x&-&2y&=&-9
  \end{array}
\]
I stedet for at skrive det op som ovenfor, kan vi skrive det op som en liste af tal på \emph{matrixform:}
\[
  \begin{pNiceMatrix}[first-col,first-row]
    & x & y & \text{konstant}\\
    \text{ligning 1} & 2 & 1 & -3\\
    \text{ligning 2} & 4 & -2 & -9
  \end{pNiceMatrix}
\]
Hver \emph{række} i matricen repræsenterer en af ligningerne. Den første \emph{søjle} af matricen repræsenterer koefficienterne foran \(x\) i ligninerne, mens den anden repræsenterer koefficienterne foran \(y\). Den sidste søje repræsenterer konstantleddet i de to ligninger. Vi kunne også have skrevet matricen som
\[
  \begin{pmatrix}
    1 & 2 & -3\\
    -2 & 4 & -9
  \end{pmatrix},
\]
hvor vi altså har byttet om på \(x\) og \(y\)'s plads: Ligningssystemet er stadig det samme; vi har bare byttet om på pladserne for variablerne. Så længe én bestemt række altid svarer til \emph{præcis ét} variabel, så er det en gyldig måde at skrive systemet op på. Dog er den sidste række \emph{altid} den, som svarer til konstantleddene. Derfor skriver vi også nogle gange matricen som
\[
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}
\]
Helt generelt definerer vi nu matricer
\begin{definition}
  En \emph{reel} \(m\times n\) matrix, eller en matrix med \(m\) rækker og \(n\) søjler, er en liste af tal
  \[
    \begin{pmatrix}
      a_{11} & a_{12} &\ldots & a_{1n}\\
      a_{21} & a_{22} & \ldots & a_{2n}\\
      \vdots & \vdots & \ddots & \vdots\\
      a_{m1} & a_{m2} & \ldots & a_{mn}
    \end{pmatrix}
  \]
  hvor hvert \(a_{ij}\) ligger i \(\R\). Mængden af alle \(m\times n\)-matricer skriver vi som \(M_{m\times n}(\R)\). Hvis \(n=m\) skriver vi dog \(M_n(\R):=M_{n\times n}(\R)\).
\end{definition}
Vi har nu en generel måde at skrive \(n\) lineære ligninger i \(n\) variable op i en \(n\times (n+1)\)-matrix: Hvis vi har et system af ligninger
\[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{llllllllcl}
  a_{1,1}x_1&+&a_{1,2}x_2&+&\dots &+&a_{1,n}x_n&=&b_1\\
  a_{2,1}x_1&+&a_{2,2}x_2&+&\dots &+&a_{2,n}x_n&=&b_2\\
    &&&&&&&\hspace{2.5pt}\vdots&\\
  a_{m,1}x_1&+&a_{m,2}x_2&+&\dots &+&a_{m,n}x_n&=&b_m
  \end{array}
  \]
  får vi på naturlig vis en matrix
  \[
    \begin{pmatrix}[cccc|c]
      a_{1,1} & a_{1,2} & \ldots & a_{1,n} & b_1\\
      a_{2,1} & a_{2,2} & \ldots & a_{2,n} & b_2\\
      \vdots & \vdots & \ddots &\vdots & \vdots\\
      a_{m,1} & a_{m,2} & \ldots & a_{m,n} & b_m
    \end{pmatrix}.
  \]
    \emph{Men hvad kan vi bruge det til?}
\subsection*{Småt og godt om lineære ligningssystemer}
  Vi laver nu nogle generelle observationer om lineære ligningssystemer. Til det bruger vi igen vores modeleksempel
  \[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&+&y&=&-3\\
    4x&-&2y&=&-9
  \end{array}
  \]
  Vi kan lægge \(-3\) til på begge sider af ligning nr. 2, og få en ækvivalent ligning.
  \begin{align*}
    4x-2y-3=-9-3\\
    \Leftrightarrow 4x-2y+(-3)=-12.
  \end{align*}
  Men vi kan bruge ligning 1 til at skrive \(-3\) om
  \begin{align*}
    4x-2y+2x+y=-12\\
    \Leftrightarrow 6x-y=-12.
  \end{align*}
  Vores oprindelige ligningssystem bliver altså nu til det ækvivalente ligningssystem
  \[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&+&y&=&-3\\
    6x&-&y&=&-12
  \end{array}
  \]
  Det giver os en generel regel:
  \begin{observation}\label{obs:adder}
    \emph{i et lineært ligningssystem kan man lægge én ligning til en anden ligning og få et ækvivalent ligningssystem.}
  \end{observation}
  Vi kan omsætte vores observation til matricen som svarer til ligningssystemet. Det svarer til at lægge række 1 (\(R_1\)) til række 2 (\(R_2\))
  \[
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}
  \xRightarrow{R_2\to R_2+R_1}
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    6 & -1 & -12
  \end{pmatrix}
\]
Lad nu \(a\) være et reelt tal. Observer da at ligningen
\[
2x+y=-3
\]
er ækvivalent med
\[
  a(2x+y)=(a)(-3)
\]
\textbf{så længe \(a\neq 0\)}, fordi vi kan gange med \(1/a\) for at få den oprindelige ligning tilbage. Det følger os til en ny observation.
\begin{observation}\label{obs:skaler}
  I et lineært ligningssystem kan man gange en ligning med et tal forskelligt fra 0 og få et ækvivalent ligningssystem.
\end{observation}
Det vil sige at matricerne
 \[   
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}
 \]
 og
 \[   
  \begin{pmatrix}[cc|c]
    a\cdot 2 & 1\cdot a & -3\cdot a\\
    4 & -2 & -9
  \end{pmatrix}
 \]
 repræsenterer ækvivalente ligningssystemer, altså ligningssystemer hvis løsninger er det samme.
\subsection*{Rækkeoperationer}
Ud fra det forhenværende delafsnit kan vi nu komme frem til nogle operationer, som vi kan udføre på en matrix, uden at ændre på ligningssystemet, som repræsenteres. Inden vi gør det, bemærker vi lige en sidste ting.
\begin{observation}\label{obs:byt}
  Hvis man bytter om på to rækker i en matrix, indkoder den det samme ligningssystem som før.
\end{observation}
I praksis: Matricerne
 \[   
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}
 \]
 og
 \[   
  \begin{pmatrix}[cc|c]
    4 & -2 & -9\\
    2 & 1 & -3
  \end{pmatrix}
 \]
 indkoder det samme ligningssystem. Nu kan vi endelig definere \emph{rækkeoperationerne}.
 \begin{definition}
   Lad
   \[
     A=
    \begin{pmatrix}
      a_{11} & a_{12} &\ldots & a_{1n}\\
      a_{21} & a_{22} & \ldots & a_{2n}\\
      \vdots & \vdots & \ddots & \vdots\\
      a_{m1} & a_{m2} & \ldots & a_{mn}
    \end{pmatrix}
   \]
   være en \(m\times n\) reel matrix. Følgende operationer kaldes \emph{rækkeoperationer} på matricen:
   \begin{enumerate}
     \item At bytte om på to rækker i \(A\).
     \item At gange en række i \(A\) med et reelt tal forskelligt fra \(0\).
     \item At lægge én række i \(A\) til en anden række i \(A\). (eller alternativt, kombinere 2 og 3 til at gange en række med et tal \(a\neq 0\), så lægge den til en anden række, og så gange den første række med \(1/a\), så den er som før).
   \end{enumerate}
 \end{definition}
 Ved brug af Observationerne \ref{obs:adder}, \ref{obs:skaler} og \ref{obs:byt} opnår vi følgende:
 \begin{proposition}
   Lad \(A,B\in M_{m\times n}(\R)\) være matricer. Hvis man kan nå frem til \(B\) fra \(A\) med endeligt mange rækkeoperationer, så repræsenterer \(A\) og \(B\) ækvivalente lineære ligningssystemer, altså:
   \begin{itemize}
   \item Systemet repræsenteret af \(A\) har en løsning hvis og kun hvis systemet repræsenteret af \(B\) har løsning;
     \item Løsningsmængden for det ene system er præcis løsningsmængden for det andet system.
   \end{itemize}
 \end{proposition}
 \subsection*{Gau\ss elimination, for real}
 Rækkeoperationer er det værktøj, som vi vil bruge til at løse lineære ligningssystemer.
 \begin{definition}
   Lad \(A\) være en \(m\times n\)-matrix. Hvis en række \(R\) i \(A\) \emph{ikke} kun består af 0'er, så kalder vi den første plads i rækken fra venstre, hvor der er et tal forskelligt fra nul, for den ledende plads. Hvis \(R\) kun består af 0'er, siger vi at dens ledende plads er \(\infty\).
 \end{definition}
 \begin{eksempel}\label{eks:3b3}
   I matricen
   \[
     \begin{pmatrix}
       0 & 3 & 1\\
       0 & 0 & 6\\
       1 & 0 & 7 
     \end{pmatrix}\in M_3(\R)
   \]
   er den ledende plads på række 1 den 2. plads. Den ledende plads på række 2 er den 3. plads, og den ledende plads på række 3 er den 1. plads.
 \end{eksempel}
 \begin{definition}
   En \(m\times n\) matrix \(A\) er på \emph{række-echelon form} hvis følgende gælder:

   For enhver række \(R\) i \(A\) er den ledende plads længere til højre (altså større) end den ledende plads i rækken over \(R\).
 \end{definition}
 \begin{eksempel}
   Matricen fra eksempel \ref{eks:3b3} er \emph{ikke} på række-echelon form, da den ledende plads på række 3 er længere til venstre end den ledende plads på række 2. Matricen
   \[
     \begin{pmatrix}
       0 &2& 1& -1\\
       0 & 0 & 3 &1\\
       0&0&0&0
     \end{pmatrix}
   \]
   er dog på række-echelon form (\(\infty>3\)). Til gengæld er matricen
   \[
     \begin{pmatrix}
       1 & 1\\
       1 & 1
     \end{pmatrix}
     \]
     ikke på række-echelon form.
 \end{eksempel}
 Hvis nu
 \[
    A=\begin{pmatrix}[ccc|c]
      a_{1,1} & a_{1,2} &  a_{1,3} & b_1\\
      a_{2,1} & a_{2,2} & a_{2,3} & b_2\\
      a_{3,1} & a_{3,2} & a_{3,3} & b_3
    \end{pmatrix}
 \]
 indkoder et ligningssystem, og \(A\) er på række-echeon-form, altså
 \[
    A=\begin{pmatrix}[ccc|c]
      a_{1,1} & a_{1,2} &  a_{1,3} & b_1\\
      0 & a_{2,2} & a_{2,3} & b_2\\
      0 &0 & a_{3,3} & b_3
    \end{pmatrix},
 \]
 så repræsenterer \(A\) ligningerne
 \begin{align*}
   a_{1,1} x_1+a_{1,2}x_2+a_{1,3}x_3&=b_2\\
   a_{2,2}x_2+a_{2,3}x_3&=b_2\\
   a_{3,3}x_3&=b_3,
 \end{align*}
 i de ubekendte \(x_1,x_2,x_3\), og så kan vi jo nemt aflæse løsningen ved at bemærke at \(x_3=b_1/a_{3,3}\), \(x_2=\frac{b_2-a_{2,3}x_3}{a_{2,2}}\), etc, hvis altså \(a_{1,1},a_{2,2},a_{3,3}\neq 0\). Hvis de ikke alle er forskellige fra 0 kan man stå i et par forskellige situationer.
 \begin{enumerate}
 \item Systemet har ingen løsninger. Det sker hvis man får en række hvor alle pladser er 0, ud over den sidste plads, hvor der er et tal \(b\neq 0\). Det ville nemlig svare til at
   \[
     0=0x_1+0x_2+\ldots+0x_n=b\neq 0,
     \]
     hvilket er umuligt. Alternativt kan man stå i følgende situation i stedet:
  \item Der er \emph{frie variable} i systemet; variable hvis værdi vi kan vælge til at være hvad som helst, og stadig opnå en løsning til systemet.
 \end{enumerate}
 Vi kommer til at kigge på begge situationer i eksempler. Nøgleobservationen er dog følgende
 \begin{observation}
   Man kan løse et lineært ligningssystem (hvis det har en løsning) ved at udføre rækkeoperationer på systemets matrix indtil den opnår række-echelon form.
 \end{observation}
 \begin{definition}
   \emph{Gau\ss}-elimination af en matrix er at udføre rækkeoperationer på matricen indtil den opnår række-echelonform.
 \end{definition}
 \begin{eksempel}
   Vi ønsker at løse vores model-eksempel med Gau\ss-elimination. Betragt ligningssystemet
\[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&+&y&=&-3\\
    4x&-&2y&=&-9
  \end{array}
\]
og dets tilhørende matrix
\[
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}.
\]
På den første række i matricen er den ledende plads 1. Vi skal derfor have gjort tallet på række 2, søjle 1 til et 0. Det kan vi gøre med en rækkeoperation:
\[
  \begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    4 & -2 & -9
  \end{pmatrix}\xRightarrow{R_2\to R_2-2\cdot R_1}\begin{pmatrix}[cc|c]
    2 & 1 & -3\\
    0 & -4 &-3 
  \end{pmatrix}.
  \]
  Det giver os ligningerne
  \begin{align*}
    -4y&=-3\\
    2x+y&=-3.
  \end{align*}
  Man kan nu finde \(y\) ved at dividere med \(-4\) i den første ligning, og så sætte \(y\) ind i den anden ligning. Så får man, som vi også så i det første afsnit, at \(x=\frac{-15}{8}\), \(y=\frac{3}{4}\)
 \end{eksempel}
Godt nok var det simplere for os at Gau\ss-eliminere systemet end at regne det direkte, men der er måske ikke så tydelig en fordel når kun vi har to ligninger og to ubekendte. I næste afsnit vil vi blandt andet kigge på større ligningssystemer.
 \subsection*{Gau\ss-Jordan elimination}
 Hvis man ikke gider lave det ekstra arbejde med at finde værdierne af sine variable efter at have Gau\ss-elimineret en matrix, så kan man Gau\ss-Jordan eliminere den. I Gau\ss-Jordan elimination reducerer man en matrix til \emph{reduceret} række-echelon form. Det betyder at for enhver række \(R\) i vores matrix gælder følgende:
 \begin{enumerate}
 \item Tallet på den ledende plads er 1
   \item Hvis den ledende plads på \(R\) er \(n\), så er tallet på plads \(n\) på alle andre rækker lig med 0.
 \end{enumerate}
 \begin{eksempel}
   Matricen
   \[
     \begin{pmatrix}
    2 & 1 & -3\\
    0 & -4 &-3 
     \end{pmatrix}
     \]
     er \emph{ikke} på reduceret række-echelonform, men matricen
     \[
       \begin{pmatrix}
         0 & 1 & 0 & 0 & 4\\
         0 & 0 & 1 & 0 & 0\\
         0 & 0 & 0 & 0 & 1
       \end{pmatrix}
     \]
     er til gengæld.
 \end{eksempel}
 Fordelen ved Gau\ss-Jordan elimination er at det er nemmere at aflæse løsningen fra matricen; ulempen er at man skal bruge flere rækkeoperationer.
 \subsection*{Eksempler}
 Lad os eliminere nogle matricer
 \begin{eksempel}
   Vi er givet ligningssystemet
   \begin{align*}
     -2x+2y+z&=7\\
     2x-8y+5z&=0\\
     19x-10y+22z&=3.
   \end{align*}
   Vi skriver den tilsvarende matrix op,
   \[
     \begin{pmatrix}[ccc|c]
       -2 & 2 & 1 & 7\\
       2 & -8 & 5 &  0\\
       19 & -10 & 22 & 3
     \end{pmatrix},
   \]
   og udfører nu Gau\ss-Jordan elimination. Vi skal først have nuller på plads 1 på alle rækker under række 1, mens vi skal have ændret \(-2\) på række 1, plads 1 til \(1\)
   \begin{gather*}
     \begin{pmatrix}[ccc|c]
       -2 & 2 & 1 & 7\\
       2 & -8 & 5 &  0\\
       19 & -10 & 22 & 3
     \end{pmatrix}
     \xRightarrow{R_2\to R_2+R_1}
     \begin{pmatrix}[ccc|c]
       -2 & 2 & 1 & 7\\
       0 & -6 & 6 &  7\\
       19 & -10 & 22 & 3
     \end{pmatrix}\\
     \xRightarrow{R_1\to -\frac{1}{2}R_1}
     \begin{pmatrix}[ccc|c]
       1 & -1 & -1/2 & -7/2\\
       0 & -6 & 6 &  7\\
       19 & -10 & 22 & 3
     \end{pmatrix}\\
     \xRightarrow{R_3\to R_3-19\cdot R_1}
     \begin{pmatrix}[ccc|c]
       1 & -1 & -1/2 & -7/2\\
       0 & -6 & 6 &  7\\
       0 & 9 & 22+19/2 & 3+133/2
     \end{pmatrix}= \begin{pmatrix}[ccc|c]
       1 & -1 & -1/2 & -7/2\\
       0 & -6 & 6 &  7\\
       0 & 9 & 63/2 & 139/2
     \end{pmatrix}.
   \end{gather*}
   Vi skal nu udføre samme process for række 2. Bemærk at både pladserne over og under den førende plads skal blive 0.
   \begin{gather*}
    \begin{pmatrix}[ccc|c]
       1 & -1 & -1/2 & -7/2\\
       0 & -6 & 6 &  7\\
       0 & 9 & 63/2 & 139/2
    \end{pmatrix}
    \xRightarrow{R_2\to -\frac{1}{6}R_2}
    \begin{pmatrix}[ccc|c]
       1 & -1 & -1/2 & -7/2\\
       0 & 1 & -1 &  -7/6\\
       0 & 9 & 63/2 & 139/2
    \end{pmatrix}\\
    \xRightarrow{R_1\to R_1+R_2}
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -7/2-7/6\\
       0 & 1 & -1 &  -7/6\\
       0 & 9 & 63/2 & 139/2
    \end{pmatrix}=
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 9 & 63/2 & 139/2
    \end{pmatrix}\\
    \xRightarrow{R_3\to R_3-9\cdot R_2}
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 0 & 63/2+18/2 & 139/2+63/6
    \end{pmatrix}=
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 0 & 81/2 & 480/6
    \end{pmatrix}\\=
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 0 & 81/2 & 80
    \end{pmatrix}.
   \end{gather*}
   Nu skal processen bare udføres for række 3.
   \begin{gather*}
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 0 & 81/2 & 80
    \end{pmatrix}
    \xRightarrow{R_3\to R_3\cdot 2/81}
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & -1 &  -7/6\\
       0 & 0 & 1 & 160/81 
    \end{pmatrix}\\
    \xRightarrow{R_2\to R_2+R_3}
    \begin{pmatrix}[ccc|c]
       1 & 0 & -3/2 & -14/3\\
       0 & 1 & 0 &  -7/6+160/81\\
       0 & 0 & 1 & 160/81 
    \end{pmatrix}\\
    \xRightarrow{R_1\to R_1+3/2R_3}
    \begin{pmatrix}[ccc|c]
       1 & 0 & 0 & -14/3+480/162\\
       0 & 1 & 0 &  -7/6+160/81\\
       0 & 0 & 1 & 160/81 
    \end{pmatrix}\\=
    \begin{pmatrix}[ccc|c]
       1 & 0 & 0 & -46/27\\
       0 & 1 & 0 &  131/162\\
       0 & 0 & 1 & 160/81 
    \end{pmatrix}
   \end{gather*}
   Altså har vi løst ligningssystemet.
 \end{eksempel}
 \begin{eksempel}[Et uløseligt ligningssystem]
   Betragt ligningsssytemet
   \[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{rcrcl}
    2x&-&y&=&-3\\
    4x&-&2y&=&-9.
  \end{array}
  \]
  Ved Gau\ss-Jordan elimination fås
  \begin{gather*}
    \begin{pmatrix}[cc|c]
      2 & -1 & -3\\
      4 & -2 & -9
    \end{pmatrix}
    \xRightarrow{R_2\to R_2-2\cdot R_1}
    \begin{pmatrix}[cc|c]
      2 & -1 & -3\\
      0 & 0 & -3
    \end{pmatrix}\\
    \xRightarrow{R_1\to \frac{1}{2}R_1}
    \begin{pmatrix}[cc|c]
      1 & -1/2 & -3/2\\
      0 & 0 & -3
    \end{pmatrix}.
  \end{gather*}
  Det viser at vores oprindelige ligningssystem er ækvivalent med
  \begin{align*}
    x-\frac{y}{2}=-\frac{3}{2}\\
    0=-3.
  \end{align*}
  Men \(0=-3\) er ikke muligt, hvilket vil sige at ligningssystemet er \emph{ukonsistent}, og at der derfor ingen løsning findes.
 \end{eksempel}
 \begin{eksempel}[Frie variable]
   Betragt matricen
   \[
     \begin{pmatrix}[ccc|c]
       1 & 0 & -3 & 7\\
       0 & 1 & 2 & -5\\
       0 & 0 & 0 & 0
     \end{pmatrix}.
   \]
   Den svarer til ligningssystemet
   \begin{align*}
     x_1-3x_3&=7\\
     x_2+2x_3&=-5.
   \end{align*}
   Altså får vi
   \[
     x_1=7-3x_3, \quad x_2=-5-2x_3.
   \]
   Bemærk at uanset hvilket \(x_3\) vi vælger, så er kan vi få en løsning til ligningssystemet ved at vælge \(x_1\) og \(x_2\) ud for ovenstående ligning. Det vil sige, at \(x_3\) er et \emph{frit variabel}: Vi kan vælge det til at være hvad som helst, og stadig få en løsning til ligningssystemet. Dette er en effekt af at der er en række i matricen, som kun består af 0'er. Vi har altså egentlig flere ligninger end variable.
 \end{eksempel}
\section{At regne med matricer}
\subsection*{Regneoperationerne}
Givet to matricer
\[
  A=\begin{pmatrix}
    a_{11} & a_{12} & \dots & a_{1n}\\
    a_{21} & a_{22} & \dots & a_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    a_{n1} & a_{n2} & \dots & a_{nn}\\
  \end{pmatrix},\quad
  B=\begin{pmatrix}
    b_{11} & b_{12} & \dots & b_{1n}\\
    b_{21} & b_{22} & \dots & b_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    b_{n1} & b_{n2} & \dots & b_{nn}\\
  \end{pmatrix}
\]
i \(M_n(\R)\) Kan vi definere deres sum til at være
\[
  A+B:=\begin{pmatrix}
    a_{11}+b_{11} & a_{12}+b_{12} & \dots & a_{1n}+b_{1n}\\
    a_{21} +b_{21} &a_{22}+ b_{22} & \dots & a_{2n}+b_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    a_{n1}+b_{n1} & a_{n2}+b_{n2} & \dots & a_{nn}+b_{nn}\\
  \end{pmatrix},
\]
altså bare den matrix hvor vi har lagt hver indgang i \(A\) sammen med den tilsvarende indgang i \(B\). Bemærk at matricerne her bliver nødt til at have samme dimension, altså vi kan ikke gøre dette hvis \(A\in M_n(\R)\) og \(B\in M_m(\R)\) og \(m\neq n\). Givet et reelt tal \(c\in\R\) kan vi også definere hvad det vil sige at \emph{skalere} en matrix:
\[
  c\cdot A:=\begin{pmatrix}
    c\cdot a_{11} & c\cdot a_{12} & \dots & c\cdot a_{1n}\\
    c\cdot a_{21} & c\cdot a_{22} & \dots & c\cdot a_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    c\cdot a_{n1} & c\cdot a_{n2} & \dots & c\cdot a_{nn}\\
  \end{pmatrix}.
\]
Man kan være fristet til at definere multiplikation af matricer på samme måde, men det viser sig ikke at være så interessant. I stedet definerer vi det på en lidt \emph{cursed måde}. Men der er en årsag, som I vil se senere: Netop at vi kan bruge matrixmultiplikation på den måde, som vi nu vil definere den til at indkode og arbejde med lineære ligningssystemer på en anden måde end vi hidtil har gjort. 

Vi lader nu \(C\in M_{m\times n}\) og \(D\in M_{n\times p}\) være matricer. Bemærk at deres dimension ikke behøver være ens, så længe \(C\) har lige så mange søjler, som \(D\) har rækker. Det vil sige at de hver især har formen
\[
  C=\begin{pmatrix}
    c_{11} & c_{12} & \dots & c_{1n}\\
    c_{21} & c_{22} & \dots & c_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    c_{m1} & c_{m2} & \dots & c_{mn}\\
  \end{pmatrix},\quad
  D=\begin{pmatrix}
    d_{11} & d_{12} & \dots & d_{1p}\\
    d_{21} & d_{22} & \dots & d_{2p}\\
    \vdots & \vdots & \ddots & \vdots \\
    d_{n1} & d_{n2} & \dots & d_{np}\\
  \end{pmatrix}
\]

Produktet af \(C\) og \(D\) er en matrix \(E\in M_{m\times p}\) ved formlen
\[
  CD:=
  \begin{pmatrix}
    e_{11} & e_{12} & \dots & e_{1p}\\
    e_{21} & e_{22} & \dots & e_{2p}\\
    \vdots & \vdots & \ddots & \vdots \\
    e_{m1} & e_{m2} & \dots & e_{mp}
  \end{pmatrix},
\]
hvor \(e_{jk}\), tallet på række \(j\) og søjle \(k\) er givet ved
\[
  e_{jk}=c_{j1}\cdot d_{1k}+c_{j2}\cdot d_{2k}+\dots+c_{jn}+d_{nk}.
\]
Bemærk at denne konstruktion netop kun giver mening når \(C\) har lige så mange søjler som \(D\) har rækker. Ellers ville man enten løbe tør for \(c\)'er eller \(d\)'er i summen.

Der er en måde at visualisere det på: For at få tallet i \(E\) på række \(j\) og søjle \(k\), skal man tage række \(j\) i \(C\) og søjle \(k\) i \(D\). Her skal man så gange det første tal i rækken med det første i søjlen og så videre derhenad, og så tage en sum til sidst.\footnote{Hvis man kender til prikproduktet mellem vektorer, så svarer det til at tage prikproduktet mellem række \(j\) i \(C\) og søjle \(k\) i \(D\).}
\[
  \begin{pNiceMatrix}[margin]
    c_{11} & c_{12} & \dots & c_{1n}\\
    \Block[draw,fill=blue!15,rounded-corners]{1-4}{}
    c_{21} & c_{22} & \dots & c_{2n}\\
    \vdots & \vdots & \ddots & \vdots \\
    c_{m1} & c_{m2} & \dots & c_{mn}\\
  \end{pNiceMatrix}
  \begin{pNiceMatrix}[margin]
    d_{11} &\Block[draw,fill=blue!15,rounded-corners]{4-1}{} d_{12} & \dots & d_{1p}\\
    d_{21} & d_{22} & \dots & d_{2p}\\
    \vdots & \vdots & \ddots & \vdots \\
    d_{n1} & d_{n2} & \dots & d_{np}\\
  \end{pNiceMatrix}=\begin{pNiceMatrix}[margin]
    e_{11} & e_{12} & \dots & e_{1p}\\
    e_{21} & \Block[draw,fill=blue!15,rounded-corners]{1-1}{}e_{22} & \dots & e_{2p}\\
    \vdots & \vdots & \ddots & \vdots \\
    e_{m1} & e_{m2} & \dots & e_{mp}
  \end{pNiceMatrix}
\]
\textbf{Bemærk at det ikke nødvendigvis gælder at \(AB=BA\) for to matricer \(A,B\in M_n(\C)\).}
\begin{eksempel}
  Vi ganger to \(2\times 2\)-matricer sammen:
  \begin{gather*}
    \begin{pmatrix}
      1 & 2\\
      3 & 4
    \end{pmatrix}\begin{pmatrix}
      2 & 0\\
      5 & -3
    \end{pmatrix}=\begin{pmatrix}
      1\cdot 2+2\cdot 5&1\cdot 0+2\cdot(-3)\\
      3\cdot 2+4\cdot 5& 3\cdot 0+4\cdot(-3)
    \end{pmatrix}\\=\begin{pmatrix}
      12 & -6\\
      26 & -12
    \end{pmatrix}
  \end{gather*}
  Et andet eksempel er:
  \begin{gather*}
    \begin{pmatrix}
      0 & 5 & -4\\
      4 & -3 & -4\\
      5 & 1 & 0
    \end{pmatrix}\begin{pmatrix}
      4\\
      4\\
      2
    \end{pmatrix}=\begin{pmatrix}
      0\cdot 4+5\cdot 4+(-4)\cdot 2\\
      4\cdot 4+(-3)\cdot 4+(-4)\cdot 2\\
      5\cdot 4+1\cdot 4+0\cdot 2
    \end{pmatrix}\\
    =\begin{pmatrix}
      12\\
      -4\\
      24
    \end{pmatrix}
  \end{gather*}
\end{eksempel}
\section*{Identiteten og inverser}
Lad os nu kun betragte de \emph{kvadratiske matricer}, altså matricerne i \(M_{n\times n}(\R)=M_n(\R)\) for et eller andet \(n\). Vi definerer nu \emph{identitetsmatricen}, \(I_n\).
\begin{definition}
  Lad \(n\) være et naturligt tal. Da er \emph{identitetsmatricen} \(I_n\in M_n(\R)\) matricen med \(n\) rækker og søjler givet ved
  \[
    \begin{pmatrix}
      1 & 0 & \ldots & 0\\
      0 & 1 & \ldots & 0\\
      \vdots & \vdots &\ddots &\vdots\\
      0 & 0 & \ldots & 1
    \end{pmatrix},
  \]
  altså matricen med 1 på diagonalen og 0 alle andre steder.
\end{definition}
Identitetsmatricen får dens navn af en meget specifik årsag.
\begin{proposition}
  Lad \(A\in M_n(\R)\). Da er
  \[
    I_nA=AI_n=A.
  \]
  Desuden, hvis \(B\in M_{n\times m}(\R)\), så er
  \[
    I_nB=B,
  \]
  og ligeledes hvis \(C\in M_{m\times n}(\R)\), så er
  \[
    CI_n=C
  \]
\end{proposition}
Med andre ord, så gør multiplikation med identitetsmatricen \emph{ingenting}.
\begin{definition}
  Vi siger at en matrix \(A\in M_n(\R)\) er \emph{invertibel} hvis der findes en matrix \(B\in M_n(\R)\), således at
  \[
    AB=I_n=BA.
  \]
  Hvis \(A\) er invertibel, så er matricen \(B\) som opfylder ovenstående ligning den \emph{eneste} matrix som opfylder ligningen, og vi kalder \(B\) for \(A\)'s invers, og skriver \(B=A^{-1}\).
\end{definition}
\subsection*{Matrixmultiplikation og lineære ligningssystemer}
Vi går nu tilbage til lineære ligningssystemer. Lad 
\[
  \arraycolsep=1.4pt%\def\arraystretch{2.2}
  \begin{array}{llllllllcl}
  a_{1,1}x_1&+&a_{1,2}x_2&+&\dots &+&a_{1,n}x_n&=&b_1\\
  a_{2,1}x_1&+&a_{2,2}x_2&+&\dots &+&a_{2,n}x_n&=&b_2\\
    &&&&&&&\hspace{2.5pt}\vdots&\\
  a_{n,1}x_1&+&a_{n,2}x_2&+&\dots &+&a_{n,n}x_n&=&b_n
  \end{array}
\]
Være et system med \(n\) ligninger og \(n\) variable. Med vores viden om matrixmultiplikation kan vi nu skrive ligningen op på mere kompakt form, nemlig som \emph{en enkelt} lineær ligning med matricer.
\[
  A\mathbf x=\mathbf b,
\]
hvor
\[
  A=\begin{pmatrix}
    a_{1,1}&a_{1,2}&\ldots & a_{1,n}\\
    a_{2,1}&a_{2,2}&\ldots & a_{2,n}\\
    \vdots&\vdots&\ddots&\vdots \\
    a_{n,1}&a_{n,2}&\ldots & a_{n,n}
  \end{pmatrix}
\]
er \(n\times n\)-matricen med koefficienter for \(x_1,\ldots,x_n\),
\[
  \mathbf x=\begin{pmatrix}
    x_1\\
    x_2\\
    \vdots \\
    x_n
  \end{pmatrix}
\]
er \(n\times 1\)-matricen af variable i ligningssystemet, og
\[
  \mathbf b=\begin{pmatrix}
    b_1\\
    b_2\\
    \vdots \\
    b_n
  \end{pmatrix}
\]
er \(n\times 1\)-matricen af konstantled. Denne repræsentation kommer vi til at arbejde med i opgaverne, og er ofte sådan man ville skrive et lineært ligningssystem i \(n\) variable og \(n\) ligninger op i praksis.
\section{Opgaver}

\begin{Exercise}
  Betragt systemet af lineære ligninger
  \begin{align*}
    3x+2y&=-1\\
    4x+y&=-2\\
    6x+4y&=3.
  \end{align*}
\Question Skriv systemet op i en matrix.
\Question Gau\ss-eliminer den resulterende matrix. Har ligningssystemet en løsning?
\end{Exercise}

\begin{Exercise}
  Betragt systemet af lineære ligninger
  \begin{align*}
    6x-y+2z=1\\
    5x-3y+3z=4\\
    3x-2y+z=14
  \end{align*}
\Question Skriv systemet op i en matrix.
\Question Gau\ss-eliminer den resulterende matrix. Har ligningssystemet en løsning?
\Question Skriv systemet op som en enkelt lineær matrixligning
\[
  A\mathbf x=\mathbf b
\]
\end{Exercise}
\begin{Exercise}
  Find to \(2\times 2\)-matricer \(A\) og \(B\) sådan at \(AB\neq BA\).
\end{Exercise}
\begin{Exercise}[label={ex:rowop}]
  Lad \(A\) være en \(n\times n\) matrix. Det viser sig at det at udføre rækkeoperationer på \(A\) faktisk bare svarer til at gange med nogle særligt udvalgte matricer. Vi kommer i den følgende opgave til at arbejde med et par eksempler.

  Lad 
  \[
    B=\begin{pmatrix}
      b_{11} & b_{12} & b_{13}\\
      b_{21} & b_{22} & b_{23}\\
      b_{31} & b_{32} & b_{33}
    \end{pmatrix}
  \]
  være en \(3\times 3\) matrix.
  \Question Find en \(3\times 3\) matrix \(C\) sådan at
  \[
    CB=\begin{pmatrix}
      b_{21} & b_{22} & b_{23}\\
      b_{11} & b_{12} & b_{13}\\
      b_{31} & b_{32} & b_{33}
    \end{pmatrix},
  \]
  dvs. at venstremultiplikation med \(C\) bytter om på række 1 og række 2 i \(B\).
  \Question Lad nu \(a\neq 0\) være et reelt tal. Find en \(3\times 3\) matrix \(D\) sådan at
  \[
    DB=
    \begin{pmatrix}
      b_{11} & b_{12} & b_{13}\\
      b_{21} & b_{22} & b_{23}\\
      a\cdot b_{31} & a\cdot b_{32} & a\cdot b_{33}
    \end{pmatrix},
  \]
  dvs. at venstremultiplikation med \(D\) er det samme som at gange række 3 i \(B\) med \(a\).
  \Question Find en \(3\times 3\) matrix \(E\) så
  \[
    EB=\begin{pmatrix}
      b_{11} & b_{12} & b_{13}\\
      b_{11}+b_{21} & b_{12}+b_{22} & b_{13}+b_{23}\\
      b_{31} & b_{32} & b_{33}
    \end{pmatrix},
  \]
  altså venstremultiplikation med \(E\) svarer til at lægge række 1 sammen med række 2 i \(B\).
  \Question Vis at alle de matricer du har fundet i denne opgave er invertible ved at finde en invers for hver matrix. (Hint: Overvej hvilken rækkeoperation du kan bruge til at gøre effekten af matricerne om).
\end{Exercise}
\begin{Exercise}
  Lad \(A\) og \(B\) være to invertible \(n\times n\) matricer. Vis at \(AB\) er invertibel, og at \((AB)^{-1}=B^{-1}A^{-1}\).
\end{Exercise}
\begin{Exercise}
  Lad \(A\) være en \(n\times n\) matrix og \(b\) være en \(n\times 1\) matrix.
  \Question Vis at ligningen
  \[
    A\mathbf x=\mathbf b
  \]
  hvor \(\mathbf x\) er en \(n\times 1\) matrix af variable har en løsning hvis \(A\) er invertibel.
  \Question (Svær) Vis at hvis ligningen 
  \[
    A\mathbf x=\mathbf b
  \]
  har en (og kun én) løsning, så er \(A\) invertibel.

  \textbf{Hint:} Hvis ligningen har en entydig løsning kan vi via rækkeoperationer omdanne
  \[
    \begin{pmatrix}[cccc|c]
      a_{11}&a_{12}&\ldots & a_{1n} & b_1\\
      a_{21}&a_{22}&\ldots & a_{2n} & b_2\\
      \vdots & \vdots & \ddots & \vdots &\vdots\\
      a_{n1}&a_{n2}&\ldots & a_{nn} & b_n
    \end{pmatrix}
   \]
   til 
   \[
    \begin{pmatrix}[cccc|c]
      1&0&\ldots & 0 & c_1\\
      0&1&\ldots & 0 & c_2\\
      \vdots & \vdots & \ddots & \vdots &\vdots\\
      0&0&\ldots & 1 & c_n
    \end{pmatrix}
  \]
  for nogle reelle tal \(c_1,c_2,\ldots c_n\). Det svarer til at gange på venstre side med rækkeoperationsmatricer som dem fra opgave \ref{ex:rowop} (som er invertible) på begge sider af lighedstegnet indtil der står \(I_n\mathbf x\) på venstresiden og
  \[
    \mathbf c:=\begin{pmatrix}
      c_1\\
      c_2\\
      \vdots \\
      c_n
    \end{pmatrix}
  \]
  på højresiden. Benyt nu at produkter af invertible matricer er invertible.
\end{Exercise}
\begin{Exercise}
  Vis at \(AB=BA\) for alle matricer i \(M_1(\R)\).
\end{Exercise}
\begin{Exercise}
  Lad \(A\) og \(B\) være to invertible \(n\times n\) matricer. Vis at hvis
  \[
    AB^{-1}=B^{-1}A,
  \]
  så er
  \[
    A^{-1}B=BA^{-1}
  \]
\end{Exercise}
\end{document}
